# Testing

parzig tries to test against the testing data provided in https://github.com/apache/parquet-testing.

parzig includes parquet-testing as a submodule in [`./testdata/parquet-testing`](./testdata/parquet-testing) and includes test cases in [`./src/parquet_testing.zig`](./src/parquet_testing.zig).

| File                                             | Status | Reason                    |
| ------------------------------------------------ | ------ | ------------------------- |
| `alltypes_dictionary.parquet`                    | âœ…     |                           |
| `alltypes_plain.parquet`                         | âœ…     |                           |
| `alltypes_plain.snappy.parquet`                  | âœ…     |                           |
| `alltypes_tiny_pages.parquet`                    | âœ…     |                           |
| `alltypes_tiny_pages_plain.parquet`              | âœ…     |                           |
| `binary.parquet`                                 | âœ…     |                           |
| `byte_array_decimal.parquet`                     | âœ…     |                           |
| `byte_stream_split.zstd.parquet`                 | âœ…     |                           |
| `byte_stream_split_extended.gzip.parquet`        | âœ…     |                           |
| `column_chunk_key_value_metadata.parquet`        | âœ…     |                           |
| `concatenated_gzip_members.parquet`              | ğŸš§     | Multi-part GZIP           |
| `data_index_bloom_encoding_stats.parquet`        | âœ…     |                           |
| `data_index_bloom_encoding_with_length.parquet`  | âœ…     |                           |
| `datapage_v1-corrupt-checksum.parquet`           | âœ…     |                           |
| `datapage_v1-snappy-compressed-checksum.parquet` | âœ…     |                           |
| `datapage_v1-uncompressed-checksum.parquet`      | âœ…     |                           |
| `datapage_v2.snappy.parquet`                     | âœ…     |                           |
| `delta_binary_packed.parquet`                    | âœ…     |                           |
| `delta_byte_array.parquet`                       | âœ…     |                           |
| `delta_encoding_optional_column.parquet`         | âœ…     |                           |
| `delta_encoding_required_column.parquet`         | âœ…     |                           |
| `delta_length_byte_array.parquet`                | âœ…     |                           |
| `dict-page-offset-zero.parquet`                  | âœ…     |                           |
| `fixed_length_byte_array.parquet`                | ğŸš§     | Malformed file            |
| `fixed_length_decimal.parquet`                   | âœ…     |                           |
| `fixed_length_decimal_legacy.parquet`            | âœ…     |                           |
| `float16_nonzeros_and_nans.parquet`              | âœ…     |                           |
| `float16_zeros_and_nans.parquet`                 | âœ…     |                           |
| `hadoop_lz4_compressed.parquet`                  | âœ…     |                           |
| `hadoop_lz4_compressed_larger.parquet`           | ğŸš§     | LZ4 (Hadoop) large file   |
| `incorrect_map_schema.parquet`                   | ğŸš§     | Non-standard MAP schema   |
| `int32_decimal.parquet`                          | âœ…     |                           |
| `int32_with_null_pages.parquet`                  | âœ…     |                           |
| `int64_decimal.parquet`                          | âœ…     |                           |
| `large_string_map.brotli.parquet`                | ğŸš§     | BROTLI compression        |
| `list_columns.parquet`                           | âœ…     |                           |
| `lz4_raw_compressed.parquet`                     | âœ…     |                           |
| `lz4_raw_compressed_larger.parquet`              | ğŸš§     | LZ4 (raw) compression     |
| `map_no_value.parquet`                           | âœ…     |                           |
| `nan_in_stats.parquet`                           | âœ…     |                           |
| `nation.dict-malformed.parquet`                  | âœ…     |                           |
| `nested_lists.snappy.parquet`                    | ğŸš§     | Deeply nested lists       |
| `nested_maps.snappy.parquet`                     | ğŸš§     | Deeply nested maps        |
| `nested_structs.rust.parquet`                    | âœ…     |                           |
| `non_hadoop_lz4_compressed.parquet`              | ğŸš§     | LZ4 compression           |
| `nonnullable.impala.parquet`                     | âœ…     |                           |
| `null_list.parquet`                              | âœ…     |                           |
| `nullable.impala.parquet`                        | ğŸš§     | Deeply nested lists       |
| `nulls.snappy.parquet`                           | âœ…     |                           |
| `old_list_structure.parquet`                     | âœ…     |                           |
| `overflow_i16_page_cnt.parquet`                  | âœ…     |                           |
| `page_v2_empty_compressed.parquet`               | âœ…     |                           |
| `plain-dict-uncompressed-checksum.parquet`       | âœ…     |                           |
| `repeated_no_annotation.parquet`                 | âœ…     |                           |
| `repeated_primitive_no_list.parquet`             | âœ…     |                           |
| `rle-dict-snappy-checksum.parquet`               | âœ…     |                           |
| `rle-dict-uncompressed-corrupt-checksum.parquet` | âœ…     |                           |
| `rle_boolean_encoding.parquet`                   | âœ…     |                           |
| `single_nan.parquet`                             | âœ…     |                           |
| `sort_columns.parquet`                           | âœ…     |                           |

## Failing Test Categories

The failing tests (ğŸš§) can be grouped into the following categories:

### Files with Special Issues

#### `fixed_length_byte_array.parquet`
- **parzig**: Unsupported fixed-length size (11 bytes)
- **Pandas/PyArrow**: Cannot read (OSError: "Unexpected end of stream")
- **Status**: Malformed file or unsupported edge case

### Deeply Nested Types
parzig now has full support for basic nested types (LIST, MAP, STRUCT) with proper Dremel-based reconstruction using definition and repetition levels. However, some files with specific nested structures still have issues:
- `nested_lists.snappy.parquet` - Triple-nested LIST columns (list<list<list<str>>>): file parses without crashing but returns all null values instead of actual data
- `nested_maps.snappy.parquet` - MAP columns with nested MAP values (fails with empty encoded_values in RLE decoder)
- `nullable.impala.parquet` - LIST of LIST columns (fails with empty encoded_values in RLE decoder)

**Supported nested features:**
- âœ… Basic LIST columns with nullable elements (`list_columns.parquet`)
- âœ… MAP columns with key-value pairs (`map_no_value.parquet`)
- âœ… STRUCT columns with multiple fields (`nested_structs.rust.parquet`)
- âœ… REPEATED fields with and without LIST annotation (`repeated_no_annotation.parquet`, `nonnullable.impala.parquet`)
- âœ… Definition and repetition level reconstruction

**Known limitations:**
- âŒ Multi-level nested LISTs (list<list<T>>): Files parse but return incorrect null values
- âŒ Nested MAP values (map<K, map<K2, V2>>): RLE decoder fails with empty encoded_values

### Compression
These files use compression codecs that have partial or no support:

**LZ4:**
âœ… Basic support implemented for Hadoop LZ4 format (codec value 5) and raw LZ4 blocks (codec value 7)
- âœ… `hadoop_lz4_compressed.parquet` - Working
- ğŸš§ `hadoop_lz4_compressed_larger.parquet` - Large file issue (EndOfStream during decompression)
- ğŸš§ `lz4_raw_compressed_larger.parquet` - File format quirk (invalid match offset)
- ğŸš§ `non_hadoop_lz4_compressed.parquet` - Syscall error

**BROTLI:**
- `large_string_map.brotli.parquet`

**Note on LZ4 Compression:**
The Parquet format specifies two different LZ4 compression codecs:
- **LZ4** (codec value 5): Deprecated codec with Hadoop framing (4-byte size prefixes)
- **LZ4_RAW** (codec value 7): Modern codec using pure LZ4 block format

parzig supports both formats with circular buffer handling for large decompressed data (>64KB sliding window).

### Multi-part GZIP
This file uses concatenated GZIP members which requires special handling:
- `concatenated_gzip_members.parquet`

### Non-standard Schema
This file has a non-spec-compliant MAP schema (optional keys instead of required):
- `incorrect_map_schema.parquet`
